{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATA ENGINEER - PYTHON PYSPARK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This test consits of fifteen problems. You are required to write your code in cell below each problem and output the result in cell next to it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INSTRUCTIONS:\n",
    "    1. You are required to download and import five CSV files, one json file and one xml file\n",
    "    2. You would need to understand business involved behind CRM database tables. This is important\n",
    "    3. Code must be in Python3/PySpark3\n",
    "    4. Either your code should output something or leave the comment \"#solution code here\" as it is. We shall use 'Run All' in notebook and it shouldn't result error\n",
    "    5. Test the entire notebook before uploading to Google Form provided\n",
    "    6. You can use any Python3 library (two are imported already) or PySpark3 library. There is no restriction\n",
    "    7. Output fieldname to be displayed are marked as single quaotes '' in problem statement. You should use same field alias names whereever required\n",
    "    8. Notation for dataframe and/or array must be local to a problem's solution. Eg. Dataframe \"test\" for problem 8 should be df_prb8_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### imports for pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as func\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21/07/21 23:02:31 WARN Utils: Your hostname, AS-MAC-0048.local resolves to a loopback address: 127.0.0.1; using 192.168.50.161 instead (on interface en0)\n",
      "21/07/21 23:02:31 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "21/07/21 23:02:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "# creating sparkcontext\n",
    "spark = SparkSession.builder.master(\"local[*]\").appName(\"assignmet\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import CSV here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Reading all 5 csv files\n",
    "df_accounts = spark.read.option(\"header\", True).csv(\"./data/accounts.csv\")\n",
    "df_products = spark.read.option(\"header\", True).csv(\"./data/products.csv\")\n",
    "df_sales_teams = spark.read.option(\"header\", True).csv(\"./data/sales_teams.csv\")\n",
    "df_clicks = spark.read.option(\"header\", True).csv(\"./data/clicks.csv\")\n",
    "df_sales_pipeline = spark.read.option(\"header\", True).csv(\"./data/sales_pipeline.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+--------------+-----------------+-----------+------------+----------+-----------+----------+\n",
      "|         account|opportunity_id|      sales_agent| deal_stage|     product|close_date|close_value|created_on|\n",
      "+----------------+--------------+-----------------+-----------+------------+----------+-----------+----------+\n",
      "|      Sunnamplex|      67HY0MW7|    Donn Cantrell|        Won|    GTXBasic|2017-05-06|      500.0|2017-04-24|\n",
      "|            null|      MA82HVCI|   James Ascencio|In_Progress|      GTXPro|      null|       null|2017-06-15|\n",
      "|            null|      BRL1KVVH|   Vicki Laflamme|       Lost|    GTXBasic|2017-08-03|        0.0|2017-05-19|\n",
      "|           Silis|      R22O68FF|  Niesha Huffines|        Won|    GTXBasic|2017-06-27|      524.0|2017-03-21|\n",
      "|           Silis|      J78AK31N|    Kami Bicknell|        Won|      MGRPFU|2017-08-04|     4794.0|2017-05-15|\n",
      "|    Groovestreet|      8I9PRPGN|Versie Hillebrand|        Won|      MGRPFS|2017-05-27|       67.0|2017-04-16|\n",
      "|         Donware|      4VHUTHOJ|    Kami Bicknell|        Won|GTXPlusBasic|2017-11-12|     1480.0|2017-11-11|\n",
      "|Wonka Industries|      TMJ0OJ0B|  Kary Hendrixson|        Won|    GTXBasic|2017-07-10|      635.0|2017-06-30|\n",
      "|            null|      NOGYL390|  Kary Hendrixson|       Lost|  GTXPlusPro|2017-07-02|        0.0|2017-04-24|\n",
      "|            null|      B22V5Z3B|    Kami Bicknell|       Lost|    GTXBasic|2017-08-07|        0.0|2017-07-25|\n",
      "|        Faxquote|      MD4PBMNN|    Anna Snelling|        Won|      MGRPFU|2017-10-24|     3842.0|2017-07-21|\n",
      "|      Zathunicon|      1XPVT5AY|  Kary Hendrixson|        Won|  GTXPlusPro|2017-10-07|     5055.0|2017-08-11|\n",
      "|            null|      ADWOMVPI|   Vicki Laflamme|In_Progress|      MGRPFS|      null|       null|2017-11-11|\n",
      "|      Stanredtax|      IH2QISS9|  Kary Hendrixson|        Won|      GTXPro|2017-05-05|     4889.0|2017-01-31|\n",
      "|          Cheers|      7JJ73XCX|   James Ascencio|        Won|GTXPlusBasic|2017-06-26|     1226.0|2017-04-26|\n",
      "|            null|      9WU5D31I|  Darcel Schlecht|In_Progress|  GTXPlusPro|      null|       null|2017-10-17|\n",
      "|     Good Burger|      T8QRTV6F|   James Ascencio|        Won|  GTXPlusPro|2017-12-22|     9150.0|2017-12-12|\n",
      "|      Lexiqvolax|      C7NFUAR6|Marty Freudenburg|        Won|GTXPlusBasic|2017-06-19|     1380.0|2017-04-15|\n",
      "|         Nam-zim|      NXRZZBVS|  Lajuana Vencill|        Won|      MGRPFU|2017-05-16|     3620.0|2017-03-25|\n",
      "|        Ron-tech|      H7ZQUWDJ|     Reed Clapper|        Won|    GTXBasic|2017-12-30|      660.0|2017-12-21|\n",
      "+----------------+--------------+-----------------+-----------+------------+----------+-----------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sales_pipeline.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import JSONs here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading Json file\n",
    "df_Orchestra = spark.read.json(\"./data/Orchestra.json\", multiLine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer & Use five CSVs to answer problem 1-10 below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 1: Display 'Manager' and 'Grand Total Sales', for sales done by the sales agents reporting these managers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+-----------------+\n",
      "|         manager|Grand Total Sales|\n",
      "+----------------+-----------------+\n",
      "|    Celia Rouche|        2518466.0|\n",
      "|   Rocco Neubert|        3346813.0|\n",
      "|   Summer Sewald|        2915362.0|\n",
      "|   Melvin Marxen|        4265901.0|\n",
      "|      Cara Losch|        1861751.0|\n",
      "|Dustin Brinkmann|        3028635.0|\n",
      "+----------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join dataframe df_sales_teams and df_sales_pipeline on sales_agent and select \"manager\" and \"close_value\"columns.\n",
    "# typecast close_value\" from string to Double type\n",
    "# Groupby the selected dataframe on \"manager\" with sum on \"close_value\"\n",
    "\n",
    "df_sales_teams.join(df_sales_pipeline, on=['sales_agent'], how='inner').\\\n",
    "select(\"manager\", \"close_value\").\\\n",
    "withColumn(\"close_value\", df_sales_pipeline[\"close_value\"].cast(DoubleType())).\\\n",
    "groupBy('manager').agg(sum('close_value').alias('Grand Total Sales')).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 2: Display 'Sales Agents' and 'Sales' for those sales where product sold at profit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------+\n",
      "|       sales_agent| sales|\n",
      "+------------------+------+\n",
      "|     Kami Bicknell|4794.0|\n",
      "| Versie Hillebrand|  67.0|\n",
      "|     Kami Bicknell|1480.0|\n",
      "|    James Ascencio|9150.0|\n",
      "| Marty Freudenburg|1380.0|\n",
      "|      Reed Clapper| 660.0|\n",
      "|      Reed Clapper|4750.0|\n",
      "| Marty Freudenburg|  75.0|\n",
      "|  Gladys Colclough|1524.0|\n",
      "|      Reed Clapper|7007.0|\n",
      "|    Wilburn Farren|1566.0|\n",
      "|   Kary Hendrixson|1631.0|\n",
      "|      Reed Clapper|6894.0|\n",
      "|      Elease Gluck|4712.0|\n",
      "|Jonathan Berthelot|1307.0|\n",
      "|      Elease Gluck|4389.0|\n",
      "|       Moses Frase|1509.0|\n",
      "|   Darcel Schlecht| 875.0|\n",
      "|   Niesha Huffines| 688.0|\n",
      "|     Kami Bicknell|  66.0|\n",
      "+------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# join 2 dataframes \"df_sales_pipeline\" and \"df_products\" on \"product\"\n",
    "# select \"sales_agent\", \"close_value\", and \"sales_price\" where \"close_value\" > \"sales_price\"(profit)\n",
    "# Rename \"close_value\" to \"sales\" and show 1st 20 records\n",
    "\n",
    "df_sales_pipeline.join(df_products, on=['product'], how='inner').\\\n",
    "select(\"sales_agent\", \"close_value\", \"sales_price\").\\\n",
    "where(col('close_value') > col('sales_price')).drop('sales_price').\\\n",
    "withColumnRenamed('close_value', 'sales').show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 3: Display the 'Opportunity ID' and 'Days Taken to Close', for opportunities those got closed within a month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------------------+\n",
      "|opportunity_id|Days Taken to Close|\n",
      "+--------------+-------------------+\n",
      "|      67HY0MW7|                 12|\n",
      "|      4VHUTHOJ|                  1|\n",
      "|      TMJ0OJ0B|                 10|\n",
      "|      B22V5Z3B|                 13|\n",
      "|      T8QRTV6F|                 10|\n",
      "|      H7ZQUWDJ|                  9|\n",
      "|      KJ1JOOQ0|                 13|\n",
      "|      88MXDSGR|                  9|\n",
      "|      4RE1ST7V|                 22|\n",
      "|      4FJHFAH7|                  6|\n",
      "|      H0NRZ2VX|                 22|\n",
      "|      VB2E4FRU|                  8|\n",
      "|      FLXHSKT4|                 13|\n",
      "|      FJVFOQPG|                 12|\n",
      "|      WHRDPR4H|                 12|\n",
      "|      LWZPACKS|                  7|\n",
      "|      377G0K33|                  2|\n",
      "|      IF0LPAQA|                 15|\n",
      "|      NEJZ68R1|                  5|\n",
      "|      ZQLLEUES|                 13|\n",
      "+--------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select \"opportunity_id\", \"close_date\" and \"created_on\" from df_deals_close\n",
    "# typecast close_date\" and \"created_on\" to Date from String\n",
    "# Add a new column \"Days Taken to Close\" which stores the number of days taken to close the deal\n",
    "# Filter the dataframe where days taken to close the deal exceeds 1 month.\n",
    "# ASSUMPTIONS: 1 month = 31 days\n",
    "# show 1st 20 records\n",
    "\n",
    "df_deals_close = df_sales_pipeline.select(\"opportunity_id\", \"close_date\", \"created_on\").\\\n",
    "withColumn(\"close_date\", df_sales_pipeline[\"close_date\"].cast(DateType())).\\\n",
    "withColumn(\"created_on\", df_sales_pipeline[\"created_on\"].cast(DateType()))\n",
    "\n",
    "df_deals_close.withColumn(\"Days Taken to Close\", datediff(df_deals_close.close_date, df_deals_close.created_on)).\\\n",
    "drop(\"close_date\", \"created_on\").where(col(\"Days Taken to Close\") < 31).show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 4: Display product(s) got maximum leads (by count) generated from paid source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----+\n",
      "|     product|count|\n",
      "+------------+-----+\n",
      "|    GTXBasic|71644|\n",
      "|GTXPlusBasic|66316|\n",
      "|      GTXPro|55036|\n",
      "|      MGRPFS|53306|\n",
      "|      MGRPFU|46500|\n",
      "|  GTXPlusPro|37029|\n",
      "|     GTK500U| 1409|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Join df_sales_pipeline and df_clicks on column \"created_on\"\n",
    "# select \"source\" and \"product\" \n",
    "# filter dataframe where \"source\" is of type \"Paid\"\n",
    "# GropBy on product with count as agg\n",
    "# sort the product in descending order to show maximum leads 1st\n",
    "\n",
    "df_sales_pipeline.join(df_clicks, on=[\"created_on\"], how=\"inner\").\\\n",
    "select(\"source\", \"product\").\\\n",
    "where(col(\"source\") == \"Paid\").\\\n",
    "groupBy(\"product\").\\\n",
    "count().\\\n",
    "sort(col(\"count\").desc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 5: Display 'Sales Agent' and 'Opportunity Count', for those sales agents who lost atleast two opportunties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+\n",
      "|       sales_agent|Opportunity Count|\n",
      "+------------------+-----------------+\n",
      "|   Darcel Schlecht|              337|\n",
      "|     Kami Bicknell|              134|\n",
      "|    Vicki Laflamme|              162|\n",
      "|      Elease Gluck|               62|\n",
      "|Jonathan Berthelot|              185|\n",
      "|   Daniell Hammack|               80|\n",
      "|     Anna Snelling|              140|\n",
      "|      Cassey Cress|              137|\n",
      "|     Garret Kinder|               63|\n",
      "|    Markita Hansen|              115|\n",
      "|      Reed Clapper|               87|\n",
      "|Rosie Papadopoulos|               56|\n",
      "|   Maureen Marcano|              119|\n",
      "|  Violet Mclelland|              111|\n",
      "|  Gladys Colclough|              149|\n",
      "|         Boris Faz|               63|\n",
      "|    Wilburn Farren|               44|\n",
      "| Versie Hillebrand|              118|\n",
      "| Marty Freudenburg|              120|\n",
      "|    Cecily Lampkin|               86|\n",
      "+------------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select \"sales_agent\" and \"close_date\" from \"df_sales_pipeline\" where \"deal_stage\" is of type \"Lost\"\n",
    "# group By \"sales_agent\" with agg count on \"sales_agent\"\n",
    "# rename count to \"Opportunity Count\" \n",
    "# Filter the dataframe where \"Opportunity Count\" is greater than 2\n",
    "# show 1st 20 records\n",
    "\n",
    "df_sales_pipeline.select(\"sales_agent\", \"close_date\").\\\n",
    "where(col(\"deal_stage\") == \"Lost\").groupBy(\"sales_agent\").\\\n",
    "agg(count(\"sales_agent\").alias(\"Opportunity Count\")).\\\n",
    "where(col(\"Opportunity Count\") >= 2).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 6: Display in ascending order of revenue, 'Account' and 'Revenue' for telecom accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             Account|           Revenue|\n",
      "+--------------------+------------------+\n",
      "|          Fasehatice|31161.600000000813|\n",
      "|            Kan-code| 54538.29999999796|\n",
      "|          Stanredtax| 70918.05000000104|\n",
      "|           Konmatfix| 93330.00000000156|\n",
      "|           Treequote|120103.30000000342|\n",
      "|              Yearin|149309.75999999608|\n",
      "|         Donquadtech|175523.04000000394|\n",
      "|Olivia Pope & Ass...| 180111.6600000033|\n",
      "|           Warephase|194623.79999999597|\n",
      "|         Iselectrics|267140.01000000624|\n",
      "|            Betatech| 288499.3199999981|\n",
      "|     Sterling Cooper| 295050.2099999969|\n",
      "|            Rangreen| 318580.0799999948|\n",
      "|        Soylent Corp|335654.28000002034|\n",
      "|              Hatfan| 363699.5799999936|\n",
      "|           Ganjaflex|381847.99999998364|\n",
      "|            Blackzim| 402422.4000000091|\n",
      "|         Good Burger|436569.50999998517|\n",
      "|            Xx-zobam| 463243.6799999794|\n",
      "|               Hooli| 471548.7200000122|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Filter df_clicks where \"industry\" is of type \"Telecom\"\n",
    "# join \"df_clicks\" with \"df_sales_pipeline\" and \"df_accounts\" on \"created_on\" and \"account\" respectively\n",
    "# Select \"Account\" and \"Revenue\" and group By on \"Account\" with agg as Sum on \"Revenue\"\n",
    "# Sort the resulting Dataframe in ascending order of \"Revenue\"\n",
    "# Show top 20 records\n",
    "\n",
    "df_clicks.where(col(\"industry\") == \"Telecom\").\\\n",
    "join(df_sales_pipeline, on=[\"created_on\"], how=\"inner\").\\\n",
    "join(df_accounts, on=['account'], how='inner').\\\n",
    "select(\"Account\", \"Revenue\").\\\n",
    "groupBy(\"Account\").\\\n",
    "agg(sum(\"Revenue\").alias(\"Revenue\")).\\\n",
    "sort(col(\"Revenue\").asc()).show()\n",
    "                                                                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 7: Display by revenue generated, bottom five 'Industries' and 'Revenue'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            industry|             Revenue|\n",
      "+--------------------+--------------------+\n",
      "|           Education| 1.239683809399929E8|\n",
      "|         Health Care| 1.613712810999844E8|\n",
      "|Retail/Entertainment|1.6403756983998743E8|\n",
      "|                  IT|1.9574398637998018E8|\n",
      "|                SaaS|2.7779542166999525E8|\n",
      "+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#solution code here\n",
    "df_clicks.join(df_sales_pipeline, on=[\"created_on\"], how=\"inner\").\\\n",
    "join(df_accounts, on=[\"account\"], how=\"inner\").\\\n",
    "select(\"created_on\", \"industry\", \"account\", \"revenue\").\\\n",
    "groupBy(\"industry\").agg(sum(\"revenue\").alias(\"Revenue\")).\\\n",
    "sort(col(\"Revenue\").asc()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 8: Display 'Month of Year' vs 'Sales', for GTXBasic. NOTE: \"Month of Year\" means month year (eg. Jan) and \"Month\" means month (eg. Jan 2020, Jan 2021 etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------+\n",
      "|Month of Year|   Sales|\n",
      "+-------------+--------+\n",
      "|            3| 28528.0|\n",
      "|            4| 28541.0|\n",
      "|            5| 56173.0|\n",
      "|            6| 73480.0|\n",
      "|            7| 85122.0|\n",
      "|            8|118306.0|\n",
      "|            9|163735.0|\n",
      "|           10|130083.0|\n",
      "|           11| 50605.0|\n",
      "|           12|132490.0|\n",
      "+-------------+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#solution code here\n",
    "df_sales_pipeline.select(\"product\", \"close_value\", \"close_date\").\\\n",
    "where((col(\"product\") == \"GTXBasic\") & (col(\"close_date\") != \"NULL\")).\\\n",
    "withColumn(\"close_date\", df_sales_pipeline[\"close_date\"].cast(DateType())).\\\n",
    "withColumn(\"Month of Year\", month(\"close_date\")).\\\n",
    "groupBy(\"Month of Year\").agg(sum(\"close_value\").alias(\"Sales\")).\\\n",
    "sort(col(\"Month of Year\").asc()).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 9: Which sales agent(s) never lost a deal. Display as a dictionary {sales agent:sales}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---------+\n",
      "|       sales_agent|    sales|\n",
      "+------------------+---------+\n",
      "|   Darcel Schlecht|2282609.0|\n",
      "|     Kami Bicknell| 467043.0|\n",
      "|    Vicki Laflamme| 617627.0|\n",
      "|      Elease Gluck| 793666.0|\n",
      "|Jonathan Berthelot| 456519.0|\n",
      "|   Daniell Hammack| 575512.0|\n",
      "|     Anna Snelling| 724285.0|\n",
      "|      Cassey Cress| 879210.0|\n",
      "|     Garret Kinder| 367530.0|\n",
      "|    Markita Hansen| 480733.0|\n",
      "|      Reed Clapper| 673723.0|\n",
      "|Rosie Papadopoulos| 359671.0|\n",
      "|   Maureen Marcano| 480797.0|\n",
      "|  Violet Mclelland| 283498.0|\n",
      "|  Gladys Colclough| 568135.0|\n",
      "|         Boris Faz| 420838.0|\n",
      "|    Wilburn Farren| 221465.0|\n",
      "| Versie Hillebrand| 532287.0|\n",
      "| Marty Freudenburg| 562287.0|\n",
      "|    Cecily Lampkin| 477964.0|\n",
      "+------------------+---------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#solution code here\n",
    "df_sales_pipeline.select(\"sales_agent\", \"deal_stage\", \"close_value\").\\\n",
    "where(col(\"deal_stage\") != \"Lost\").\\\n",
    "groupBy(\"sales_agent\").agg(sum(\"close_value\").alias(\"sales\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 10: Display 'Sales Agents', 'Product', and 'Sales', for those sales agents who closed more than one deal on same day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+------------+------+\n",
      "|      sales_agent|     product| sales|\n",
      "+-----------------+------------+------+\n",
      "|    Corliss Cosme|    GTXBasic| 740.0|\n",
      "|  Daniell Hammack|      MGRPFS|  52.0|\n",
      "|    Hayden Neloms|      MGRPFU|  null|\n",
      "|  Maureen Marcano|      MGRPFS|  73.0|\n",
      "|Marty Freudenburg|GTXPlusBasic|1225.0|\n",
      "|     Reed Clapper|    GTXBasic| 771.0|\n",
      "|        Zane Levy|      MGRPFS|  90.0|\n",
      "|Marty Freudenburg|GTXPlusBasic|1185.0|\n",
      "|      Moses Frase|    GTXBasic| 467.0|\n",
      "|Versie Hillebrand|      MGRPFS|  63.0|\n",
      "|      Moses Frase|    GTXBasic| 797.0|\n",
      "|  Rosalina Dieter|      MGRPFS|  58.0|\n",
      "|  Rosalina Dieter|      MGRPFS|  78.0|\n",
      "|   Markita Hansen|      MGRPFS|  45.0|\n",
      "|   Vicki Laflamme|      MGRPFS|  65.0|\n",
      "|   Vicki Laflamme|      MGRPFS|  54.0|\n",
      "|   James Ascencio|      MGRPFS|  77.0|\n",
      "|  Niesha Huffines|GTXPlusBasic| 852.0|\n",
      "|   James Ascencio|      MGRPFS|  86.0|\n",
      "|  Darcel Schlecht|      MGRPFS|  50.0|\n",
      "+-----------------+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ASSUMPTION: Deal Close = (where deal_stage = WON)\n",
    "\n",
    "df_sales_pipeline.groupBy(\"sales_agent\", \"product\", \"close_date\", \"deal_stage\").\\\n",
    "agg(sum(\"close_value\").alias(\"sales\")).\\\n",
    "where(col(\"deal_stage\")== \"Won\").\\\n",
    "groupBy(\"sales_agent\", \"product\", \"sales\").\\\n",
    "agg(count(\"close_date\").alias(\"count\")).\\\n",
    "where(col(\"count\") >= 2).\\\n",
    "drop(\"count\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refer & Use Orchestra.json to answer problem 11-13 below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 11: Display the instrument played by Lehmann Caroline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+----------------------------------------------------+\n",
      "|Orchestra_programs_works_soloists_soloist_name|Orchestra_programs_works_soloists_soloist_Instrument|\n",
      "+----------------------------------------------+----------------------------------------------------+\n",
      "|                             Lehmann, Caroline|                                             Soprano|\n",
      "+----------------------------------------------+----------------------------------------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Flatten the nested JSON to reach to the respective JOSN field\n",
    "\n",
    "df_Orchestra_programs = df_Orchestra.withColumn(\"Orchestra_programs\", explode_outer(col(\"programs\"))).drop(\"programs\")\n",
    "\n",
    "df_Orchestra_programs_works = df_Orchestra_programs.\\\n",
    "withColumn(\"Orchestra_programs_works\", explode_outer(col(\"Orchestra_programs.works\"))).drop(\"Orchestra_programs\")\n",
    "\n",
    "df_Orchestra_programs_works_soloists = df_Orchestra_programs_works.\\\n",
    "withColumn(\"Orchestra_programs_works_soloists\", explode_outer(col(\"Orchestra_programs_works.soloists\"))).\\\n",
    "drop(\"Orchestra_programs_works\")\n",
    "\n",
    "df_Orchestra_programs_works_soloists = df_Orchestra_programs_works_soloists.\\\n",
    "withColumn(\"Orchestra_programs_works_soloists_soloist_name\", col(\"Orchestra_programs_works_soloists.soloistName\"))\n",
    "df_Orchestra_programs_works_soloists = df_Orchestra_programs_works_soloists.\\\n",
    "withColumn(\"Orchestra_programs_works_soloists_soloist_Instrument\", col(\"Orchestra_programs_works_soloists.soloistInstrument\"))\n",
    "\n",
    "df_Orchestra_programs_works_soloists = df_Orchestra_programs_works_soloists.drop(\"Orchestra_programs_works_soloists\")\n",
    "\n",
    "# Filter on soloist_name = Lehmann, Caroline\n",
    "df_Orchestra_programs_works_soloists.where(col(\"Orchestra_programs_works_soloists_soloist_name\") == \"Lehmann, Caroline\").show(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 12: Display all vocalists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------------+----------------------------------------------------+\n",
      "|Orchestra_programs_works_soloists_soloist_name|Orchestra_programs_works_soloists_soloist_Instrument|\n",
      "+----------------------------------------------+----------------------------------------------------+\n",
      "|                                 Groebl, Marie|                                            Vocalist|\n",
      "|                                  Lankow, Anna|                                            Vocalist|\n",
      "|                           Cutter-Savage, Ruby|                                            Vocalist|\n",
      "|                                  Doenhoff von|                                            Vocalist|\n",
      "|                                          Ford|                                            Vocalist|\n",
      "|                                Anderson, Sara|                                            Vocalist|\n",
      "|                               Heinrich, Julia|                                            Vocalist|\n",
      "|                               Clarke, Charles|                                            Vocalist|\n",
      "|                                   Rice, Fanny|                                            Vocalist|\n",
      "|                                        Munson|                                            Vocalist|\n",
      "|                             Elmblad, Johannes|                                            Vocalist|\n",
      "|                               Borie, Annie J.|                                            Vocalist|\n",
      "|                          Henschel, Lillian...|                                            Vocalist|\n",
      "|                          Roth-Muehl, Nicolaus|                                            Vocalist|\n",
      "|                                  Senger, Emil|                                            Vocalist|\n",
      "|                                  Jones, L. A.|                                            Vocalist|\n",
      "|                               Murska, Ilma Di|                                            Vocalist|\n",
      "|                           Galassi, Antonio F.|                                            Vocalist|\n",
      "|                               Northall, Julia|                                            Vocalist|\n",
      "|                          Huntington, Agnes B.|                                            Vocalist|\n",
      "+----------------------------------------------+----------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_Orchestra_programs_works_soloists.\\\n",
    "where(col(\"Orchestra_programs_works_soloists_soloist_Instrument\") == \"Vocalist\").\\\n",
    "distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 13: Display orchestra played under program id 2561"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+----------------------------+\n",
      "|Orchestra_programs_programID|Orchestra_programs_orchestra|\n",
      "+----------------------------+----------------------------+\n",
      "|                        2561|        New York Philharm...|\n",
      "+----------------------------+----------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flatten Dataframe\n",
    "df_Orchestra_programs = df_Orchestra_programs.withColumn(\"Orchestra_programs_programID\",  \n",
    "                                                         col(\"Orchestra_programs.programID\"))\n",
    "df_Orchestra_programs = df_Orchestra_programs.withColumn(\"Orchestra_programs_orchestra\", \n",
    "                                                         col(\"Orchestra_programs.orchestra\"))\n",
    "\n",
    "# Filter on Orchestra_programs_programID 2561 and show Orchestra_programs_orchestra\n",
    "df_Orchestra_programs.drop(\"Orchestra_programs\").where(col(\"Orchestra_programs_programID\") == \"2561\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Refer & Use Orchestra.xml to answer problem 14-15 below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read XML file\n",
    "# ASSUMPTION: used com.databricks.spark.xml jar package \n",
    "\n",
    "df_Orchestra_xml = spark.read \\\n",
    "    .format(\"com.databricks.spark.xml\") \\\n",
    "    .option(\"rootTag\", \"programs\") \\\n",
    "    .option(\"rowTag\", \"program\") \\\n",
    "    .load(\"./data/Orchestra.xml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 14: Display locations used for event at time 8:15 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|concertInfo_location|\n",
      "+--------------------+\n",
      "|        Hartford, CT|\n",
      "|        Brooklyn, NY|\n",
      "|     Springfield, MA|\n",
      "|    Indianapolis, IN|\n",
      "|      Providence, RI|\n",
      "|          Newark, NJ|\n",
      "|       Manhattan, NY|\n",
      "|    Philadelphia, PA|\n",
      "|       New Haven, CT|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Flatten nested dataframe\n",
    "\n",
    "df_Orchestra_xml_flat = df_Orchestra_xml.withColumn(\"concertInfo_location\", explode_outer(col(\"concertInfo.location\")))\n",
    "df_Orchestra_xml_flat = df_Orchestra_xml_flat.withColumn(\"concertInfo_time\", explode_outer(col(\"concertInfo.time\")))\n",
    "\n",
    "#Filter on concertInfo_time = 8:15PM and select all distinct locations\n",
    "df_Orchestra_xml_flat.where(col(\"concertInfo_time\") == \"8:15PM\").select(\"concertInfo_location\").distinct().show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow these stpes to Resolve Error: java.lang.ClassNotFoundException: Failed to find data source: com.databricks.spark.xml\n",
    "* Download spark-xml .jar file from https://mvnrepository.com/artifact/com.databricks/spark-xml_2.11/0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'posixpath' from '/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/posixpath.py'>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Copy `spark-xml` jar file to `/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/pyspark/jars` \n",
    "\n",
    "The target location is prepared with the help of output from `os.path`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PROBLEM 15: Display total number of programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1033"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Orchestra_xml.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "********************************************* Test ends here **************************************************"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
